{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C3Ixf2FoAI1"
      },
      "source": [
        "# Logistical Regression for Email Spam Detection through Homomorphic Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDI5A4DdqcUz"
      },
      "source": [
        "Based on this tutorial: https://github.com/OpenMined/TenSEAL/blob/main/tutorials%2FTutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJkNx-fBoLfM"
      },
      "source": [
        "Setup Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAQwnpY73Ta5",
        "outputId": "20c833c4-7224-48cd-ab3a-4bb0fdf7db13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXnqTDCanaeD",
        "outputId": "dcd0539b-f418-4fae-b9e1-ae6bfefcde1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import torch\n",
        "import tenseal as ts\n",
        "import random\n",
        "from time import time\n",
        "#Run the below piece of code for the first time\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3jsi1oNoWAV"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luNk6oqRjwN5"
      },
      "source": [
        "Dataset: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IP-kESzrnaeF"
      },
      "outputs": [],
      "source": [
        "message_data = pd.read_csv(\"spam.csv\",encoding = \"latin\")\n",
        "message_data.head()\n",
        "middle_index = len(message_data) // 2\n",
        "# Split the DataFrame into half\n",
        "message_data = message_data.iloc[:middle_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LPJqovooZH_"
      },
      "source": [
        "Remove Unnamed Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "20vpI8FXnaeG"
      },
      "outputs": [],
      "source": [
        "message_data = message_data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT0BdvTLogDA"
      },
      "source": [
        "# Label Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sVd31ek2naeG"
      },
      "outputs": [],
      "source": [
        "message_data = message_data.rename(columns = {'v1':'Spam/Not_Spam','v2':'message'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-NHZhdb4lOsI"
      },
      "outputs": [],
      "source": [
        "message_data['Spam/Not_Spam'] = message_data['Spam/Not_Spam'].replace({'spam': 0, 'ham': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "s4uK1Kr1naeG",
        "outputId": "8f5409fa-b1fd-430a-de56-d9748b5141e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              message         \\\n",
              "                count unique   \n",
              "Spam/Not_Spam                  \n",
              "0                 381    358   \n",
              "1                2405   2300   \n",
              "\n",
              "                                                                       \n",
              "                                                             top freq  \n",
              "Spam/Not_Spam                                                          \n",
              "0              I don't know u and u don't know me. Send CHAT ...    3  \n",
              "1                                         Sorry, I'll call later   19  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-726f6d84-8a2f-4c59-a56a-64db0405cf33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">message</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spam/Not_Spam</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>381</td>\n",
              "      <td>358</td>\n",
              "      <td>I don't know u and u don't know me. Send CHAT ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2405</td>\n",
              "      <td>2300</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-726f6d84-8a2f-4c59-a56a-64db0405cf33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-726f6d84-8a2f-4c59-a56a-64db0405cf33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-726f6d84-8a2f-4c59-a56a-64db0405cf33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1c5dea5-d57c-418a-8916-66a0ea67b868\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1c5dea5-d57c-418a-8916-66a0ea67b868')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1c5dea5-d57c-418a-8916-66a0ea67b868 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"message_data\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Spam/Not_Spam\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"message\",\n        \"count\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"381\",\n        \"max\": \"2405\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2405\",\n          \"381\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"message\",\n        \"unique\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 358,\n        \"max\": 2300,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2300,\n          358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"message\",\n        \"top\"\n      ],\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Sorry, I'll call later\",\n          \"I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"message\",\n        \"freq\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"3\",\n        \"max\": \"19\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"19\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "message_data.groupby('Spam/Not_Spam').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "urPCNe3KnaeG"
      },
      "outputs": [],
      "source": [
        "message_data_copy = message_data['message'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FxVzfs_KnaeG"
      },
      "outputs": [],
      "source": [
        "def text_preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    return \" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6Pitt7oTnaeG"
      },
      "outputs": [],
      "source": [
        "message_data_copy = message_data_copy.apply(text_preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRCEmgJwonRw"
      },
      "source": [
        "# Embed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4GO7qEJnaeG",
        "outputId": "e5268158-a220-4599-f343-2388c38405ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Go jurong point crazy Available bugis n great ...\n",
              "1                                 Ok lar Joking wif u oni\n",
              "2       Free entry 2 wkly comp win FA Cup final tkts 2...\n",
              "3                     U dun say early hor U c already say\n",
              "4             Nah dont think goes usf lives around though\n",
              "                              ...                        \n",
              "2781    likely called Mittelschmertz Google dont parac...\n",
              "2782    Well right Im gonna get check todays steam sal...\n",
              "2783                          arrived see couple days lt3\n",
              "2784                                   K wat tht incident\n",
              "2785                                   Yeah get unlimited\n",
              "Name: message, Length: 2786, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "message_data_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7sUbZZbwnaeG"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vfIVoYHknaeH"
      },
      "outputs": [],
      "source": [
        "message_mat = vectorizer.fit_transform(message_data_copy)\n",
        "message_mat\n",
        "coo = message_mat.tocoo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GHVBrtRnaeH"
      },
      "source": [
        "# Stem and Normalize length of the messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dBQI9DYLnaeI"
      },
      "outputs": [],
      "source": [
        "# Stemming: Making text easier and consistent to process\n",
        "def stemmer (text):\n",
        "    text = text.split()\n",
        "    words = \"\"\n",
        "    for i in text:\n",
        "            stemmer = SnowballStemmer(language='english')\n",
        "            words += (stemmer.stem(i))+\" \"\n",
        "    return words\n",
        "message_data_copy = message_data_copy.apply(stemmer)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "message_mat = vectorizer.fit_transform(message_data_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kJpK-JianaeI"
      },
      "outputs": [],
      "source": [
        "# Normalization: Adding string length\n",
        "message_data['length'] = message_data['message'].apply(len)\n",
        "message_data.head()\n",
        "length = message_data['length'].to_numpy()\n",
        "new_mat = np.hstack((message_mat.todense(),length[:, None]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9E8DlSspiFW"
      },
      "source": [
        "# Get Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xTUiydKXUcC",
        "outputId": "63cf21a0-9f7c-4be4-b073-4254e01f7348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "new_mat = np.asarray(new_mat)\n",
        "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(\n",
        "    new_mat,\n",
        "    message_data['Spam/Not_Spam'],\n",
        "    test_size=0.3,\n",
        "    random_state=20\n",
        ")\n",
        "print(type (spam_nospam_test))\n",
        "print(type (spam_nospam_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHqeqvzhplKU"
      },
      "source": [
        "Format data for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Aj8ofKwjd41v"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor(message_train)\n",
        "x_test = torch.FloatTensor(message_test)\n",
        "y_train = torch.FloatTensor(spam_nospam_train.values)\n",
        "y_test = torch.FloatTensor(spam_nospam_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.view(-1, 1)\n",
        "y_test = y_test.view(-1, 1)"
      ],
      "metadata": {
        "id": "SO5ZQ4wC3M4X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes of the tensors:\")\n",
        "print(f\"x_train has shape: {x_train.shape}\")\n",
        "print(f\"y_train has shape: {y_train.shape}\")\n",
        "print(f\"x_test has shape: {x_test.shape}\")\n",
        "print(f\"y_test has shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7zY50XW3uKD",
        "outputId": "dba097b0-d8bf-447c-aecb-b6bbd8bba71b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the tensors:\n",
            "x_train has shape: torch.Size([1950, 5360])\n",
            "y_train has shape: torch.Size([1950, 1])\n",
            "x_test has shape: torch.Size([836, 5360])\n",
            "y_test has shape: torch.Size([836, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7z6ihSkpvCh"
      },
      "source": [
        "# Setup LR Model (Unencrypted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV0hgNe8pnSZ"
      },
      "source": [
        "Class declaration for Logistical Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jTMuGZba3-j5"
      },
      "outputs": [],
      "source": [
        "class LR(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_features):\n",
        "        super(LR, self).__init__()\n",
        "        self.lr = torch.nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.lr(x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x_z1gfRN67x_"
      },
      "outputs": [],
      "source": [
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "# use gradient descent with a learning_rate=1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "# use Binary Cross Entropy Loss\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1tS9LDQpqWZ"
      },
      "source": [
        "# Train / Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUHvE8sV68dV",
        "outputId": "0c8034a0-9656-414e-c35f-e531036946f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 1: 0.5376841425895691\n",
            "Loss at epoch 2: 0.44197991490364075\n",
            "Loss at epoch 3: 0.44197991490364075\n",
            "Loss at epoch 4: 0.44197991490364075\n",
            "Loss at epoch 5: 0.44197991490364075\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "def train(model, optimizer, criterion, x, y, epochs=EPOCHS):\n",
        "    model.train()\n",
        "    for e in range(1, epochs + 1):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        # Ensure 'out' is [1950, 1] if your model architecture doesn't already guarantee this\n",
        "        loss = criterion(out, y)  # No need to squeeze out, y is [1950, 1]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Loss at epoch {e}: {loss.item()}\")\n",
        "    return model\n",
        "model = train(model, optimizer, criterion, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyNOMa5Q7BVl",
        "outputId": "7702c1e1-a748-4e07-e48f-a585327bccaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on plain test_set: 0.8444976210594177\n"
          ]
        }
      ],
      "source": [
        "def accuracy(model, x, y):\n",
        "    out = model(x)\n",
        "    correct = torch.abs(y - out) < 0.5\n",
        "    return correct.float().mean()\n",
        "\n",
        "plain_accuracy = accuracy(model, x_test, y_test)\n",
        "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDjVNvzdp21z"
      },
      "source": [
        "# Build Homomorphically Encrypted LR Model (Accepts Encrypted Query Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Hifoib_FmcPu"
      },
      "outputs": [],
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        # TenSEAL processes lists and not torch tensors,\n",
        "        # so we take out the parameters from the PyTorch model\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        # We don't need to perform sigmoid as this model\n",
        "        # will only be used for evaluation, and the label\n",
        "        # can be deduced without applying sigmoid\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        return enc_out\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    ################################################\n",
        "    ## You can use the functions below to perform ##\n",
        "    ## the evaluation with an encrypted model     ##\n",
        "    ################################################\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self, context):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "\n",
        "eelr = EncryptedLR(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rvz3WYpKmfq1"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "poly_mod_degree = 4096\n",
        "coeff_mod_bit_sizes = [40, 20, 40]\n",
        "# create TenSEALContext\n",
        "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "# scale of ciphertext to use\n",
        "ctx_eval.global_scale = 2 ** 20\n",
        "# this key is needed for doing dot-product operations\n",
        "ctx_eval.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tYGjIUZqX6n"
      },
      "source": [
        "# Encrypt Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2se4qlymzpO"
      },
      "outputs": [],
      "source": [
        "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2LHNOorqJKM"
      },
      "source": [
        "# Encrypt Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgFoGytXn6Sy",
        "outputId": "ab304f35-5cab-458c-d313-a12c9ec53341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n"
          ]
        }
      ],
      "source": [
        "eelr.encrypt(ctx_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-35cGShrqLmP"
      },
      "source": [
        "# Test HE Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqR8Y8NfnH2h",
        "outputId": "5c26a85a-1a98-4da2-d91f-ca3254113117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 836 entries in 31 seconds\n",
            "Accuracy: 706/836 = 0.8444976076555024\n",
            "Difference between plain and encrypted accuracies: 0.0\n"
          ]
        }
      ],
      "source": [
        "def encrypted_evaluation(model, enc_x_test, y_test):\n",
        "    t_start = time()\n",
        "\n",
        "    correct = 0\n",
        "    for enc_x, y in zip(enc_x_test, y_test):\n",
        "        # encrypted evaluation\n",
        "        enc_out = model(enc_x)\n",
        "        # plain comparison\n",
        "        out = enc_out.decrypt()\n",
        "        out = torch.tensor(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        if torch.abs(out - y) < 0.5:\n",
        "            correct += 1\n",
        "\n",
        "    t_end = time()\n",
        "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
        "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
        "    return correct / len(x_test)\n",
        "\n",
        "\n",
        "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
        "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
        "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
        "if diff_accuracy < 0:\n",
        "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZkAPa5vjSlQ"
      },
      "source": [
        "# Build Homomorphically Encrypted LR Model (Trains on Encrypted data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WjxsoDHqjYMY"
      },
      "outputs": [],
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        # we accumulate gradients and counts the number of iterations\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
        "        # update weights\n",
        "        # We use a small regularization term to keep the output\n",
        "        # of the linear layer in the range of the sigmoid approximation\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # We use the polynomial approximation of degree 3\n",
        "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
        "        # from https://eprint.iacr.org/2018/462.pdf\n",
        "        # which fits the function pretty well in the range [-5,5]\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        # evaluate accuracy of the model on\n",
        "        # the plain (x_test, y_test) dataset\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "v_2wo6JnlCOg"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "# create TenSEALContext\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj1_vyXEl1Lg"
      },
      "source": [
        "Encrypt training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKU5rcEHlIvX"
      },
      "outputs": [],
      "source": [
        "t_start = time()\n",
        "# Assuming x_train and y_train are lists of one-dimensional arrays\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvejN_odlq04"
      },
      "outputs": [],
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    # if you want to keep an eye on the distribution to make sure\n",
        "    # the function approximation is still working fine\n",
        "    # WARNING: this operation is time consuming\n",
        "    # encrypted_out_distribution(eelr, enc_x_train)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")\n",
        "\n",
        "diff_accuracy = plain_accuracy - accuracy\n",
        "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
        "if diff_accuracy < 0:\n",
        "    print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}